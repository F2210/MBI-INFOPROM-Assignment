{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc43439a",
   "metadata": {},
   "source": [
    "# Process Mining with PM4Py: Inductive Miner Variants\n",
    "\n",
    "This notebook demonstrates how to create different process models using various inductive miner implementations available in PM4Py. We'll use the filtered XES logs that were created during the preprocessing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8a37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pm4py\n",
    "import matplotlib.pyplot as plt\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "\n",
    "# Set up the path to the data folder\n",
    "data_folder = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d78d7",
   "metadata": {},
   "source": [
    "## 1. Helper Functions\n",
    "\n",
    "Let's define some helper functions to load logs, discover models, visualize them, and evaluate their quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9344e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_log(log_file_path):\n",
    "    \"\"\"\n",
    "    Load an XES log file\n",
    "    \n",
    "    Args:\n",
    "        log_file_path: Path to the XES file\n",
    "        \n",
    "    Returns:\n",
    "        PM4Py event log object\n",
    "    \"\"\"\n",
    "    print(f\"Loading log: {log_file_path}\")\n",
    "    log = xes_importer.apply(log_file_path)\n",
    "    print(f\"Log loaded with {len(log)} cases and {sum(len(case) for case in log)} events\")\n",
    "    return log\n",
    "\n",
    "def discover_models(log, variant_name, variant):\n",
    "    \"\"\"\n",
    "    Discover process models using the specified algorithm variant\n",
    "    \n",
    "    Args:\n",
    "        log: PM4Py event log\n",
    "        variant_name: String name of the variant (for display)\n",
    "        variant: The actual algorithm variant to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing process tree and Petri net with initial and final markings\n",
    "    \"\"\"\n",
    "    print(f\"\\nDiscovering models using {variant_name}...\")\n",
    "    \n",
    "    # Discover process tree\n",
    "    process_tree = inductive_miner.apply(log, variant=variant)\n",
    "    \n",
    "    # Convert to Petri net for visualization and conformance checking\n",
    "    net, initial_marking, final_marking = pm4py.convert_to_petri_net(process_tree)\n",
    "    \n",
    "    return process_tree, net, initial_marking, final_marking\n",
    "\n",
    "def visualize_models(process_tree, net, initial_marking, final_marking, variant_name, output_folder=None):\n",
    "    \"\"\"\n",
    "    Visualize both process tree and Petri net models\n",
    "    \n",
    "    Args:\n",
    "        process_tree: The process tree model\n",
    "        net: The Petri net\n",
    "        initial_marking: Initial marking for the Petri net\n",
    "        final_marking: Final marking for the Petri net\n",
    "        variant_name: String name of the variant (for display and filenames)\n",
    "        output_folder: Folder to save visualizations (if None, just display)\n",
    "    \"\"\"\n",
    "    # Visualize process tree\n",
    "    pt_gviz = pt_visualizer.apply(process_tree)\n",
    "    \n",
    "    # Visualize Petri net\n",
    "    parameters = {pn_visualizer.Variants.WO_DECORATION.value.Parameters.FORMAT: \"png\"}\n",
    "    pn_gviz = pn_visualizer.apply(net, initial_marking, final_marking, parameters=parameters)\n",
    "\n",
    "    # Display visualizations\n",
    "    if output_folder:\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pt_visualizer.save(pt_gviz, os.path.join(output_folder, f\"process_tree_{variant_name}.png\"))\n",
    "        pn_visualizer.save(pn_gviz, os.path.join(output_folder, f\"petri_net_{variant_name}.png\"))\n",
    "        print(f\"Visualizations saved to {output_folder}\")\n",
    "    else:\n",
    "        pt_visualizer.view(pt_gviz)\n",
    "        pn_visualizer.view(pn_gviz)\n",
    "\n",
    "def evaluate_model(log, net, initial_marking, final_marking, variant_name):\n",
    "    \"\"\"\n",
    "    Evaluate a process model using the four quality dimensions\n",
    "    \n",
    "    Args:\n",
    "        log: PM4Py event log\n",
    "        net: The Petri net\n",
    "        initial_marking: Initial marking for the Petri net\n",
    "        final_marking: Final marking for the Petri net\n",
    "        variant_name: String name of the variant (for display)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {variant_name} model...\")\n",
    "    \n",
    "    # Compute fitness using token-based replay\n",
    "    fitness = replay_fitness.evaluate(  \n",
    "        log=log,\n",
    "        net=net,\n",
    "        initial_marking=initial_marking,\n",
    "        final_marking=final_marking,\n",
    "        variant=replay_fitness.Variants.TOKEN_BASED\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Compute precision using ETConformance\n",
    "    precision = precision_evaluator.evaluate(   \n",
    "        log=log,\n",
    "        net=net,\n",
    "        initial_marking=initial_marking,\n",
    "        final_marking=final_marking,\n",
    "        variant=precision_evaluator.Variants.ETCONFORMANCE_TOKEN\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Compute generalization\n",
    "    generalization = generalization_evaluator.evaluate(log, net, initial_marking, final_marking)\n",
    "    \n",
    "    # Compute simplicity\n",
    "    simplicity = simplicity_evaluator.evaluate(net)\n",
    "    \n",
    "    metrics = {\n",
    "        'variant': variant_name,\n",
    "        'fitness': fitness['average_trace_fitness'],\n",
    "        'precision': precision,\n",
    "        'generalization': generalization,\n",
    "        'simplicity': simplicity\n",
    "    }\n",
    "    \n",
    "    print(f\"Fitness: {metrics['fitness']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Generalization: {metrics['generalization']:.4f}\")\n",
    "    print(f\"Simplicity: {metrics['simplicity']:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_group(log_name, output_folder=None):\n",
    "    \"\"\"\n",
    "    Process a log file using different inductive miner variants\n",
    "    \n",
    "    Args:\n",
    "        log_name: Name of the log file (without path)\n",
    "        output_folder: Folder to save visualizations\n",
    "    \n",
    "    Returns:\n",
    "        List of evaluation metrics for each variant\n",
    "    \"\"\"\n",
    "    log_path = os.path.join(data_folder, log_name)\n",
    "    \n",
    "    # If output folder is specified, create a subfolder for this log\n",
    "    if output_folder:\n",
    "        group_output_folder = os.path.join(output_folder, log_name.replace('.xes', ''))\n",
    "        os.makedirs(group_output_folder, exist_ok=True)\n",
    "    else:\n",
    "        group_output_folder = None\n",
    "    \n",
    "    # Load the log\n",
    "    log = load_log(log_path)\n",
    "    \n",
    "    # List of variants to try\n",
    "    variants = [\n",
    "        ('IM', inductive_miner.Variants.IM),\n",
    "        ('IMf', inductive_miner.Variants.IMf),\n",
    "        ('IMd', inductive_miner.Variants.IMd)\n",
    "    ]\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    # Process each variant\n",
    "    for variant_name, variant in variants:\n",
    "        # Discover models\n",
    "        process_tree, net, initial_marking, final_marking = discover_models(log, variant_name, variant)\n",
    "        \n",
    "        # Visualize models\n",
    "        visualize_models(process_tree, net, initial_marking, final_marking, variant_name, group_output_folder)\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = evaluate_model(log, net, initial_marking, final_marking, variant_name)\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "    return all_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc59ead",
   "metadata": {},
   "source": [
    "## 2. Compliance Check per Classification\n",
    "\n",
    "This analysis checks whether each purchase order case in the event log complies with the expected behavior defined by its item classification, based on the BPI Challenge 2019 documentation.\n",
    "\n",
    "3-way match, invoice after GR:\n",
    "The invoice is recorded after goods receipt, and both must exist in the trace (GR-based IV = true, Goods Receipt = true).\n",
    "\n",
    "3-way match, invoice before GR:\n",
    "The invoice can be recorded before goods receipt, but both events are still expected in the trace (GR-based IV = false, Goods Receipt = true).\n",
    "\n",
    "2-way match:\n",
    "Only an invoice is expected — no goods receipt is required (GR-based IV = false, Goods Receipt = false).\n",
    "\n",
    "Consignment:\n",
    "Goods are received but no invoice is expected or allowed (Goods Receipt = true, GR-based IV = false, and item type is consignment).\n",
    "\n",
    "\n",
    "\n",
    "NOTE: We check event order based on the first occurrence of each activity in a case. This may miss edge cases with repeated events, but offers a practical balance between accuracy and simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705e6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading log: ./data/BPI_Challenge_2019.xes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1fc50badbc4a70a8017c40a273c08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/251734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loaded with 251734 cases and 1595923 events\n",
      "3-way match, invoice after GR: ✅ 11128 | ❌ 4054\n",
      "3-way match, invoice before GR: ✅ 16360 | ❌ 204650\n",
      "2-way match: ✅ 687 | ❌ 357\n",
      "Consignment: ✅ 13466 | ❌ 1032\n",
      "Unknown: ✅ 0 | ❌ 0\n"
     ]
    }
   ],
   "source": [
    "def check_case_compliance(log):\n",
    "    \"\"\"\n",
    "    Check whether each case complies with the expected behavior\n",
    "    based on its Item Category classification.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing counts of compliant and non-compliant cases per category.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize compliance counters\n",
    "    compliance_results = {\n",
    "        \"3-way match, invoice after GR\": {\"compliant\": 0, \"non_compliant\": 0},\n",
    "        \"3-way match, invoice before GR\": {\"compliant\": 0, \"non_compliant\": 0},\n",
    "        \"2-way match\": {\"compliant\": 0, \"non_compliant\": 0},\n",
    "        \"Consignment\": {\"compliant\": 0, \"non_compliant\": 0},\n",
    "        \"Unknown\": {\"compliant\": 0, \"non_compliant\": 0}\n",
    "    }\n",
    "\n",
    "    # Analyze each case\n",
    "    for case in log:\n",
    "        category = case.attributes.get(\"Item Category\", \"Unknown\").strip()\n",
    "        events = [e[\"concept:name\"] for e in case]\n",
    "\n",
    "        # 3-way match, invoice AFTER goods receipt (GR must happen before invoice)\n",
    "        if category == \"3-way match, invoice after GR\":\n",
    "            if \"Record Goods Receipt\" in events and \"Record Invoice Receipt\" in events:\n",
    "                if events.index(\"Record Goods Receipt\") < events.index(\"Record Invoice Receipt\"):\n",
    "                    compliance_results[category][\"compliant\"] += 1\n",
    "                else:\n",
    "                    compliance_results[category][\"non_compliant\"] += 1  # wrong order\n",
    "            else:\n",
    "                compliance_results[category][\"non_compliant\"] += 1  # missing steps\n",
    "\n",
    "        # 3-way match, invoice BEFORE goods receipt\n",
    "        elif category == \"3-way match, invoice before GR\":\n",
    "            if \"Record Invoice Receipt\" in events and \"Record Goods Receipt\" in events:\n",
    "                if events.index(\"Record Invoice Receipt\") < events.index(\"Record Goods Receipt\"):\n",
    "                    compliance_results[category][\"compliant\"] += 1\n",
    "                else:\n",
    "                    compliance_results[category][\"non_compliant\"] += 1  # wrong order\n",
    "            else:\n",
    "                compliance_results[category][\"non_compliant\"] += 1\n",
    "\n",
    "        # 2-way match: invoice expected, no GR expected\n",
    "        elif category == \"2-way match\":\n",
    "            if \"Record Invoice Receipt\" in events and \"Record Goods Receipt\" not in events:\n",
    "                compliance_results[category][\"compliant\"] += 1\n",
    "            else:\n",
    "                compliance_results[category][\"non_compliant\"] += 1\n",
    "\n",
    "        # Consignment: GR expected, no invoice allowed\n",
    "        elif category == \"Consignment\":\n",
    "            if \"Record Goods Receipt\" in events and \"Record Invoice Receipt\" not in events:\n",
    "                compliance_results[category][\"compliant\"] += 1\n",
    "            else:\n",
    "                compliance_results[category][\"non_compliant\"] += 1\n",
    "\n",
    "        # Unknown or other category\n",
    "        else:\n",
    "            compliance_results[\"Unknown\"][\"non_compliant\"] += 1\n",
    "\n",
    "    return compliance_results\n",
    "\n",
    "\n",
    "log = load_log('./data/BPI_Challenge_2019.xes')\n",
    "results = check_case_compliance(log)\n",
    "\n",
    "# Pretty print\n",
    "for category, stats in results.items():\n",
    "    print(f\"{category}: ✅ {stats['compliant']} | ❌ {stats['non_compliant']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d82b6",
   "metadata": {},
   "source": [
    "## 2. Analyze Each Group\n",
    "\n",
    "Now let's process each filtered log in the data folder. We'll discover process models using different inductive miner variants for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8793023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 XES files in ./data:\n",
      "  - BPI_Challenge_2019.xes\n",
      "\n",
      "==================================================\n",
      "Processing BPI_Challenge_2019.xes\n",
      "==================================================\n",
      "Loading log: ./data/BPI_Challenge_2019.xes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2076385b6c0246e5a31f15c349883bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/251734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loaded with 251734 cases and 1595923 events\n",
      "\n",
      "Discovering models using IM...\n",
      "Visualizations saved to ./output/BPI_Challenge_2019\n",
      "\n",
      "Evaluating IM model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate() got an unexpected keyword argument 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxes_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m group_metrics = \u001b[43mprocess_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxes_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m all_results[xes_file] = group_metrics\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mprocess_group\u001b[39m\u001b[34m(log_name, output_folder)\u001b[39m\n\u001b[32m    164\u001b[39m     visualize_models(process_tree, net, initial_marking, final_marking, variant_name, group_output_folder)\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     metrics = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_marking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_marking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     all_metrics.append(metrics)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_metrics\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(log, net, initial_marking, final_marking, variant_name)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariant_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Compute fitness using token-based replay\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m fitness = \u001b[43mreplay_fitness\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_marking\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_marking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinal_marking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_marking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplay_fitness\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVariants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTOKEN_BASED\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Compute precision using ETConformance\u001b[39;00m\n\u001b[32m     95\u001b[39m precision = precision_evaluator.evaluate(   \n\u001b[32m     96\u001b[39m     log=log,\n\u001b[32m     97\u001b[39m     net=net,\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m     variant=precision_evaluator.Variants.ETCONFORMANCE_TOKEN\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: evaluate() got an unexpected keyword argument 'log'"
     ]
    }
   ],
   "source": [
    "# Find all XES files in the data folder\n",
    "xes_files = [f for f in os.listdir(data_folder) if f.endswith('.xes')]\n",
    "print(f\"Found {len(xes_files)} XES files in {data_folder}:\")\n",
    "for f in xes_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Create output folder for visualizations\n",
    "output_folder = './output'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each group\n",
    "all_results = {}\n",
    "for xes_file in xes_files:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {xes_file}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    group_metrics = process_group(xes_file, output_folder)\n",
    "    all_results[xes_file] = group_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 XES files in ./data:\n",
      "  - BPI_Challenge_2019.xes\n",
      "\n",
      "==================================================\n",
      "Processing BPI_Challenge_2019.xes\n",
      "==================================================\n",
      "Loading log: ./data\\BPI_Challenge_2019.xes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d422118a3cc44dc9889715da6a74f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/251734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loaded with 251734 cases and 1595923 events\n",
      "\n",
      "Discovering models using IM...\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphviz\\backend\\execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n",
      "\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n",
      "\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n",
      "\u001b[0;32m   1021\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n",
      "\u001b[0;32m   1022\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1025\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1026\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;32m   1034\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1509\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n",
      "\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1509\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1510\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n",
      "\u001b[0;32m   1511\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1512\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1513\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1514\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1515\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1516\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m   1518\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n",
      "\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n",
      "\u001b[0;32m   1523\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n",
      "\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxes_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m---> 18\u001b[0m group_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxes_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     19\u001b[0m all_results[xes_file] \u001b[38;5;241m=\u001b[39m group_metrics\n",
      "\n",
      "Cell \u001b[1;32mIn[2], line 150\u001b[0m, in \u001b[0;36mprocess_group\u001b[1;34m(log_name, output_folder)\u001b[0m\n",
      "\u001b[0;32m    147\u001b[0m process_tree, net, initial_marking, final_marking \u001b[38;5;241m=\u001b[39m discover_models(log, variant_name, variant)\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Visualize models\u001b[39;00m\n",
      "\u001b[1;32m--> 150\u001b[0m \u001b[43mvisualize_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_marking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_marking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_output_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n",
      "\u001b[0;32m    153\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate_model(log, net, initial_marking, final_marking, variant_name)\n",
      "\n",
      "Cell \u001b[1;32mIn[2], line 60\u001b[0m, in \u001b[0;36mvisualize_models\u001b[1;34m(process_tree, net, initial_marking, final_marking, variant_name, output_folder)\u001b[0m\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_folder:\n",
      "\u001b[0;32m     59\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m---> 60\u001b[0m     \u001b[43mpt_visualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_gviz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocess_tree_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvariant_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     61\u001b[0m     pn_visualizer\u001b[38;5;241m.\u001b[39msave(pn_gviz, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpetri_net_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariant_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizations saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pm4py\\visualization\\process_tree\\visualizer.py:78\u001b[0m, in \u001b[0;36msave\u001b[1;34m(gviz, output_file_path, parameters)\u001b[0m\n",
      "\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(gviz: graphviz\u001b[38;5;241m.\u001b[39mGraph, output_file_path: \u001b[38;5;28mstr\u001b[39m, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Save the diagram\u001b[39;00m\n",
      "\u001b[0;32m     70\u001b[0m \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m        Path where the GraphViz output should be saved\u001b[39;00m\n",
      "\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m---> 78\u001b[0m     \u001b[43mgsave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgviz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pm4py\\visualization\\common\\save.py:48\u001b[0m, in \u001b[0;36msave\u001b[1;34m(gviz, output_file_path, parameters)\u001b[0m\n",
      "\u001b[0;32m     46\u001b[0m     F\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 48\u001b[0m     render \u001b[38;5;241m=\u001b[39m \u001b[43mgviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     49\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfile(render, output_file_path)\n",
      "\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"elif not is_dot_installed:\u001b[39;00m\n",
      "\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    raise Exception(\"impossible to save formats different from HTML without the Graphviz binary\")\"\"\"\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n",
      "\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n",
      "\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n",
      "\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n",
      "\u001b[0;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n",
      "\u001b[1;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n",
      "\u001b[0;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n",
      "\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n",
      "\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n",
      "\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphviz\\backend\\rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n",
      "\u001b[0;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n",
      "\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\maxbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n",
      "\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "# Find all XES files in the data folder\n",
    "xes_files = [f for f in os.listdir(data_folder) if f.endswith('.xes')]\n",
    "print(f\"Found {len(xes_files)} XES files in {data_folder}:\")\n",
    "for f in xes_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Create output folder for visualizations\n",
    "output_folder = './output'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each group\n",
    "all_results = {}\n",
    "for xes_file in xes_files:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {xes_file}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    group_metrics = process_group(xes_file, output_folder)\n",
    "    all_results[xes_file] = group_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912d772",
   "metadata": {},
   "source": [
    "## 3. Compare Results\n",
    "\n",
    "Let's create a summary view to compare the performance of different inductive miner variants across the different process groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a dataframe with all results\n",
    "results_df = []\n",
    "for log_name, metrics_list in all_results.items():\n",
    "    for metrics in metrics_list:\n",
    "        metrics_copy = metrics.copy()\n",
    "        metrics_copy['log'] = log_name.replace('.xes', '').replace('group_', '')\n",
    "        results_df.append(metrics_copy)\n",
    "\n",
    "results_df = pd.DataFrame(results_df)\n",
    "print(results_df)\n",
    "\n",
    "# Plot the results using a heatmap for each metric\n",
    "metrics = ['fitness', 'precision', 'generalization', 'simplicity']\n",
    "\n",
    "fig, axes = plt.subplots(len(metrics), 1, figsize=(12, 4*len(metrics)))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    pivot_df = results_df.pivot(index='log', columns='variant', values=metric)\n",
    "    sns.heatmap(pivot_df, annot=True, cmap='YlGnBu', ax=axes[i])\n",
    "    axes[i].set_title(f'{metric.capitalize()} by variant and log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f1f30",
   "metadata": {},
   "source": [
    "## 4. Detailed Analysis of the \"2-way match\" Process\n",
    "\n",
    "Let's focus on the \"2-way match\" process group and analyze it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2-way match log\n",
    "two_way_log = load_log(os.path.join(data_folder, 'group_2_way.xes'))\n",
    "\n",
    "# Get some basic statistics\n",
    "print(f\"Number of cases: {len(two_way_log)}\")\n",
    "print(f\"Number of events: {sum(len(case) for case in two_way_log)}\")\n",
    "print(f\"Average events per case: {sum(len(case) for case in two_way_log) / len(two_way_log):.2f}\")\n",
    "\n",
    "# Get the most frequent variants\n",
    "variants = pm4py.get_variants(two_way_log)\n",
    "print(f\"Number of variants: {len(variants)}\")\n",
    "\n",
    "# Display top 5 variants\n",
    "variant_count = [(count, trace) for trace, count in variants.items()]\n",
    "variant_count.sort(reverse=True)\n",
    "print(\"\\nTop 5 variants:\")\n",
    "for i, (count, trace) in enumerate(variant_count[:5]):\n",
    "    activities = [event['concept:name'] for event in trace]\n",
    "    print(f\"{i+1}. Count: {count} - Activities: {' → '.join(activities)}\")\n",
    "\n",
    "# Apply the IMf variant (usually good balance between precision and generalization)\n",
    "process_tree = inductive_miner.apply_tree(two_way_log, variant=inductive_miner.Variants.IMF)\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(process_tree)\n",
    "\n",
    "# Visualize the process tree and Petri net\n",
    "pt_gviz = pt_visualizer.apply(process_tree)\n",
    "pt_visualizer.view(pt_gviz)\n",
    "\n",
    "# Perform more detailed conformance checking\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as token_replay\n",
    "replayed_traces = token_replay.apply(two_way_log, net, initial_marking, final_marking)\n",
    "\n",
    "# Analyze conformance results\n",
    "conforming_traces = [trace for trace in replayed_traces if trace['trace_is_fit']]\n",
    "print(f\"Conforming traces: {len(conforming_traces)} out of {len(replayed_traces)} ({len(conforming_traces)/len(replayed_traces)*100:.2f}%)\")\n",
    "\n",
    "# Identify problematic transitions if any\n",
    "all_transitions = set()\n",
    "activated_transitions = set()\n",
    "missing_transitions = set()\n",
    "\n",
    "for trace in replayed_traces:\n",
    "    for trans in trace['activated_transitions']:\n",
    "        all_transitions.add(trans.name)\n",
    "        activated_transitions.add(trans.name)\n",
    "    for trans in trace['missing_tokens_transitions']:\n",
    "        all_transitions.add(trans.name)\n",
    "        missing_transitions.add(trans.name)\n",
    "\n",
    "print(\"\\nActivated transitions:\", len(activated_transitions))\n",
    "print(\"Missing transitions:\", len(missing_transitions))\n",
    "if missing_transitions:\n",
    "    print(\"Problematic transitions:\", missing_transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb214f",
   "metadata": {},
   "source": [
    "## 5. Comparing Different Process Groups\n",
    "\n",
    "Let's now compare the different process groups to understand how they differ from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the logs\n",
    "logs = {}\n",
    "for xes_file in xes_files:\n",
    "    group_name = xes_file.replace('.xes', '').replace('group_', '')\n",
    "    logs[group_name] = load_log(os.path.join(data_folder, xes_file))\n",
    "\n",
    "# Compare number of variants and activities\n",
    "for group_name, log in logs.items():\n",
    "    variants = pm4py.get_variants(log)\n",
    "    activities = pm4py.get_event_attribute_values(log, \"concept:name\")\n",
    "    \n",
    "    print(f\"\\nGroup: {group_name}\")\n",
    "    print(f\"  Cases: {len(log)}\")\n",
    "    print(f\"  Events: {sum(len(case) for case in log)}\")\n",
    "    print(f\"  Variants: {len(variants)}\")\n",
    "    print(f\"  Activities: {len(activities)}\")\n",
    "    print(f\"  Events per case: {sum(len(case) for case in log) / len(log):.2f}\")\n",
    "\n",
    "# Identify common and unique activities across groups\n",
    "all_activities = {}\n",
    "for group_name, log in logs.items():\n",
    "    activities = set(pm4py.get_event_attribute_values(log, \"concept:name\").keys())\n",
    "    all_activities[group_name] = activities\n",
    "\n",
    "# Find activities that appear in all groups\n",
    "if len(all_activities) > 1:\n",
    "    common_activities = set.intersection(*all_activities.values())\n",
    "    print(f\"\\nCommon activities across all groups ({len(common_activities)}):\")\n",
    "    print(\", \".join(sorted(common_activities)))\n",
    "    \n",
    "    # Find activities unique to each group\n",
    "    for group_name, activities in all_activities.items():\n",
    "        unique_activities = activities - set.union(*(set(acts) for g, acts in all_activities.items() if g != group_name))\n",
    "        print(f\"\\nActivities unique to {group_name} ({len(unique_activities)}):\")\n",
    "        if unique_activities:\n",
    "            print(\", \".join(sorted(unique_activities)))\n",
    "        else:\n",
    "            print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc634b",
   "metadata": {},
   "source": [
    "## 6. Advanced Process Mining: Directly-Follows Graphs\n",
    "\n",
    "Let's visualize the directly-follows graphs (DFGs) for each process group, which can provide a simpler view of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.visualization.dfg import visualizer as dfg_visualizer\n",
    "\n",
    "# For each log, create and visualize a directly-follows graph\n",
    "for group_name, log in logs.items():\n",
    "    print(f\"\\nGenerating DFG for {group_name}...\")\n",
    "    \n",
    "    # Discover directly-follows graph\n",
    "    dfg, start_activities, end_activities = pm4py.discover_directly_follows_graph(log)\n",
    "    \n",
    "    # Visualize DFG\n",
    "    parameters = {dfg_visualizer.Variants.FREQUENCY.value.Parameters.FORMAT: \"png\"}\n",
    "    gviz = dfg_visualizer.apply(dfg, start_activities, end_activities, parameters=parameters)\n",
    "    \n",
    "    # Save to file\n",
    "    output_path = os.path.join(output_folder, f\"dfg_{group_name}.png\")\n",
    "    dfg_visualizer.save(gviz, output_path)\n",
    "    \n",
    "    print(f\"DFG visualization saved to {output_path}\")\n",
    "    \n",
    "    # Just for display in the notebook\n",
    "    dfg_visualizer.view(gviz)\n",
    "\n",
    "    # Also generate a performance DFG to show time differences\n",
    "    perf_dfg, perf_sa, perf_ea = pm4py.discover_performance_directly_follows_graph(log)\n",
    "    \n",
    "    # Visualize performance DFG\n",
    "    perf_gviz = dfg_visualizer.apply(perf_dfg, perf_sa, perf_ea, variant=dfg_visualizer.Variants.PERFORMANCE, \n",
    "                                 parameters=parameters)\n",
    "    \n",
    "    # Save to file\n",
    "    perf_output_path = os.path.join(output_folder, f\"perf_dfg_{group_name}.png\")\n",
    "    dfg_visualizer.save(perf_gviz, perf_output_path)\n",
    "    \n",
    "    print(f\"Performance DFG visualization saved to {perf_output_path}\")\n",
    "    \n",
    "    # Just for display in the notebook\n",
    "    dfg_visualizer.view(perf_gviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5db6b",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded and analyzed filtered XES logs for different process groups\n",
    "2. Used various inductive miner variants to discover process models\n",
    "3. Evaluated the quality of these models using standard metrics\n",
    "4. Compared different process groups\n",
    "5. Visualized models as process trees, Petri nets, and directly-follows graphs\n",
    "\n",
    "The different inductive miner variants offer different trade-offs:\n",
    "- IM (Inductive Miner): Balanced approach, guarantees sound models\n",
    "- IMf (Inductive Miner - infrequent): Filters out infrequent behavior\n",
    "- IMd (Inductive Miner - directly follows): Uses the directly-follows abstraction\n",
    "- IM_CLEAN: More aggressive filtering approach to create simpler models\n",
    "\n",
    "For further analysis, you might consider:\n",
    "- Analyzing the resource perspective (who performs which activities)\n",
    "- Analyzing the time perspective (bottlenecks, throughput times)\n",
    "- Building predictive models based on these discovered processes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
